{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b12bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "import os, json, random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "WEATHER_LABELS = (\"clear\", \"fog\", \"rain\", \"snow\")\n",
    "\n",
    "def with_weather_suffix(orig_name: str, tag: str) -> str:\n",
    "    \"\"\"'000123.jpg' + 'fog' -> '000123_fog.jpg'.\"\"\"\n",
    "    base = Path(orig_name).stem\n",
    "    return f\"{base}_{tag}.jpg\"\n",
    "\n",
    "def weather_from_filename(file_name: str) -> str:\n",
    "    \"\"\"Parse weather tag from filename; defaults to 'clear'.\"\"\"\n",
    "    tag = Path(file_name).stem.split(\"_\")[-1].lower()\n",
    "    return tag if tag in WEATHER_LABELS else \"clear\"\n",
    "\n",
    "\n",
    "# ========= CONFIG =========\n",
    "COCO_ROOT = \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1\"  # adjust\n",
    "TRAIN_IM_DIR = f\"{COCO_ROOT}/train\"\n",
    "VAL_IM_DIR   = f\"{COCO_ROOT}/valid\"\n",
    "TRAIN_ANN_IN = f\"{COCO_ROOT}/train/_annotations.coco.json\"\n",
    "VAL_ANN_IN   = f\"{COCO_ROOT}/valid/_annotations.coco.json\"\n",
    "\n",
    "OUT_ROOT     = f\"{COCO_ROOT}/ACDC-1-NEW\"  # will be created\n",
    "OUT_TRAIN_IM = f\"{OUT_ROOT}/images/train\"\n",
    "OUT_VAL_IM   = f\"{OUT_ROOT}/images/val\"\n",
    "OUT_TRAIN_JS = f\"{OUT_ROOT}/annotations/mini_train.json\"\n",
    "OUT_VAL_JS   = f\"{OUT_ROOT}/annotations/mini_val.json\"\n",
    "\n",
    "\n",
    "# pick how many final images per split\n",
    "TRAIN_TARGET = 3000\n",
    "VAL_TARGET   = 500\n",
    "\n",
    "\n",
    "# size selection: \"all\", \"small\", \"medium\", \"large\"\n",
    "SIZE_FILTER = \"all\"   # set to \"all\" | \"small\" | \"medium\" | \"large\"\n",
    "\n",
    "# COCO size rules: small < 32^2, medium in [32^2, 96^2), large >= 96^2\n",
    "# or strict max side rule if USE_COCO_AREA=False\n",
    "USE_COCO_AREA = True\n",
    "AREA_SMALL_MAX  = 32 * 32\n",
    "AREA_MED_MAX    = 96 * 96\n",
    "MAX_SIDE_SMALL  = 48\n",
    "MAX_SIDE_MEDMAX = 96\n",
    "\n",
    "# keep only annotations that match SIZE_FILTER within selected images\n",
    "KEEP_ONLY_MATCHING_ANNS = True\n",
    "\n",
    "# weather settings\n",
    "APPLY_WEATHER = False   # master switch. False means no weather, images copied as-is\n",
    "APPLY_FOG  = False\n",
    "APPLY_RAIN = False\n",
    "APPLY_SNOW = False\n",
    "WEATHER_PER_IMAGE = 3   # 1 means pick one at random, 3 means generate fog+rain+snow\n",
    "\n",
    "# DAWN-like classes\n",
    "TARGET_CLASS_NAMES = [\"person\",\"bicycle\",\"car\",\"motorcycle\",\"bus\",\"truck\"]\n",
    "# TARGET_CLASS_NAMES = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]  # DAWN-1 classes\n",
    "# Select all COCO classes without listing them one by one\n",
    "class _All:\n",
    "    def __contains__(self, _):\n",
    "        return True\n",
    "\n",
    "# TARGET_CLASS_NAMES = _All()  # means all 80 COCO classes\n",
    "\n",
    "# reproducibility\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# ========= WEATHER OPS =========\n",
    "def _gaussian_mask(h, w, sigma=0.35):\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    yy = (yy - h/2) / (sigma*h)\n",
    "    xx = (xx - w/2) / (sigma*w)\n",
    "    m = np.exp(-(xx**2 + yy**2))\n",
    "    m = (m - m.min()) / (m.max() - m.min() + 1e-8)\n",
    "    return m[..., None].astype(np.float32)\n",
    "\n",
    "def add_fog(img, strength=0.55):\n",
    "    blur = cv2.GaussianBlur(img, (0,0), sigmaX=max(3, int(0.02*max(img.shape[:2]))))\n",
    "    fog  = np.clip(blur + strength*255, 0, 255).astype(np.uint8)\n",
    "    mask = _gaussian_mask(img.shape[0], img.shape[1], sigma=0.38)\n",
    "    out  = (img*(1-mask) + fog*mask).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def add_rain(img, streaks=1100, alpha=0.20, angle_deg=18, length=(8,18)):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    ang = np.deg2rad(angle_deg)\n",
    "    c,s = np.cos(ang), np.sin(ang)\n",
    "    for _ in range(streaks):\n",
    "        L = np.random.randint(length[0], length[1]+1)\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        x2 = int(x + L*c); y2 = int(y + L*s)\n",
    "        cv2.line(overlay, (x,y), (x2,y2), (255,255,255), 1, cv2.LINE_AA)\n",
    "    overlay = cv2.blur(overlay, (3,3))\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def add_snow(img, flakes=2000, alpha=0.30):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    for _ in range(flakes):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        r = np.random.randint(1,3)\n",
    "        cv2.circle(overlay, (x,y), r, (255,255,255), -1, cv2.LINE_AA)\n",
    "    overlay = cv2.GaussianBlur(overlay, (3,3), 0)\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def weather_once(img, which):\n",
    "    if which == \"fog\":  return add_fog(img)\n",
    "    if which == \"rain\": return add_rain(img)\n",
    "    if which == \"snow\": return add_snow(img)\n",
    "    return img\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def load_json(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def ensure_dir(p):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filter_to_targets(coco):\n",
    "    keep_cat = [c for c in coco[\"categories\"] if c[\"name\"] in TARGET_CLASS_NAMES]\n",
    "    oldid2new = {c[\"id\"]: i+1 for i,c in enumerate(keep_cat)}\n",
    "    for i,c in enumerate(keep_cat):\n",
    "        c[\"id\"] = i+1\n",
    "    return keep_cat, oldid2new\n",
    "\n",
    "def coco_size_bucket(area):\n",
    "    if area < AREA_SMALL_MAX:\n",
    "        return \"small\"\n",
    "    if area < AREA_MED_MAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def side_size_bucket(w, h):\n",
    "    mx = max(w, h)\n",
    "    if mx < MAX_SIDE_SMALL:\n",
    "        return \"small\"\n",
    "    if mx < MAX_SIDE_MEDMAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def ann_size_bucket(ann):\n",
    "    x,y,w,h = ann[\"bbox\"]\n",
    "    area = ann.get(\"area\", w*h)\n",
    "    return coco_size_bucket(area) if USE_COCO_AREA else side_size_bucket(w, h)\n",
    "\n",
    "def matches_size_filter(size_name):\n",
    "    if SIZE_FILTER == \"all\":\n",
    "        return True\n",
    "    return size_name == SIZE_FILTER\n",
    "\n",
    "def choose_weathers():\n",
    "    if not APPLY_WEATHER:\n",
    "        return []\n",
    "    opts = []\n",
    "    if APPLY_FOG:  opts.append(\"fog\")\n",
    "    if APPLY_RAIN: opts.append(\"rain\")\n",
    "    if APPLY_SNOW: opts.append(\"snow\")\n",
    "    if not opts:\n",
    "        return []\n",
    "    if WEATHER_PER_IMAGE == 3:\n",
    "        return opts\n",
    "    return [random.choice(opts)]\n",
    "\n",
    "def sample_images(kept_images, target_n):\n",
    "    if len(kept_images) <= target_n:\n",
    "        return kept_images\n",
    "    return random.sample(kept_images, target_n)\n",
    "\n",
    "# ========= CORE SELECTION =========\n",
    "def collect_images_by_size(coco, img_dir):\n",
    "    keep_cats, old2new = filter_to_targets(coco)\n",
    "    # group anns by image, only target cats\n",
    "    anns_by_img_all = defaultdict(list)\n",
    "    for a in coco[\"annotations\"]:\n",
    "        if a[\"category_id\"] in old2new:\n",
    "            anns_by_img_all[a[\"image_id\"]].append(a)\n",
    "\n",
    "    # keep images that have at least one annotation matching SIZE_FILTER\n",
    "    kept_images = []\n",
    "    matched_anns_by_img = defaultdict(list)\n",
    "    for img in coco[\"images\"]:\n",
    "        iid = img[\"id\"]\n",
    "        if iid not in anns_by_img_all:\n",
    "            continue\n",
    "        p = os.path.join(img_dir, img[\"file_name\"])\n",
    "        if not os.path.isfile(p):\n",
    "            continue\n",
    "\n",
    "        anns = anns_by_img_all[iid]\n",
    "        has_match = False\n",
    "        tmp = []\n",
    "        for a in anns:\n",
    "            sz = ann_size_bucket(a)\n",
    "            if matches_size_filter(sz):\n",
    "                has_match = True\n",
    "                tmp.append(a)\n",
    "\n",
    "        if SIZE_FILTER == \"all\":\n",
    "            # any target class is fine\n",
    "            if len(anns) > 0:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = anns\n",
    "        else:\n",
    "            if has_match:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = tmp if KEEP_ONLY_MATCHING_ANNS else anns\n",
    "\n",
    "    return kept_images, matched_anns_by_img, keep_cats, old2new\n",
    "\n",
    "# ========= JSON REWRITE =========\n",
    "def rewrite_json(coco, kept_images, anns_by_img, keep_cats, old2new, new_filenames):\n",
    "    keep_img_ids = {im[\"id\"] for im in kept_images}\n",
    "    out_imgs = []\n",
    "    for im in kept_images:\n",
    "        new_file = new_filenames.get(im[\"id\"], im[\"file_name\"])\n",
    "        out_imgs.append({\n",
    "            \"id\": im[\"id\"],\n",
    "            \"file_name\": new_file,\n",
    "            \"width\": im.get(\"width\"),\n",
    "            \"height\": im.get(\"height\")\n",
    "        })\n",
    "\n",
    "    out_anns = []\n",
    "    nid = 1\n",
    "    for iid in keep_img_ids:\n",
    "        for a in anns_by_img[iid]:\n",
    "            cid_new = old2new.get(a[\"category_id\"])\n",
    "            if not cid_new:\n",
    "                continue\n",
    "            x,y,w,h = a[\"bbox\"]\n",
    "            out_anns.append({\n",
    "                \"id\": nid,\n",
    "                \"image_id\": iid,\n",
    "                \"category_id\": cid_new,\n",
    "                \"bbox\": [float(x), float(y), float(w), float(h)],\n",
    "                \"area\": float(a.get(\"area\", w*h)),\n",
    "                \"iscrowd\": int(a.get(\"iscrowd\", 0))\n",
    "            })\n",
    "            nid += 1\n",
    "\n",
    "    # safety: drop images that lost all anns\n",
    "    valid_ids = {a[\"image_id\"] for a in out_anns}\n",
    "    out_imgs = [im for im in out_imgs if im[\"id\"] in valid_ids]\n",
    "\n",
    "    return {\n",
    "        \"info\": coco.get(\"info\", {\"description\": \"COCO size-filtered mini\"}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"images\": out_imgs,\n",
    "        \"annotations\": out_anns,\n",
    "        \"categories\": keep_cats\n",
    "    }\n",
    "\n",
    "# ========= PIPELINE =========\n",
    "def process_split(img_dir, ann_in, out_img_dir, out_json_path, target_n):\n",
    "    print(f\"[SPLIT] {img_dir} size={SIZE_FILTER} weather={'on' if APPLY_WEATHER else 'off'}\")\n",
    "    coco = load_json(ann_in)\n",
    "    kept_images, anns_by_img, keep_cats, old2new = collect_images_by_size(coco, img_dir)\n",
    "    if not kept_images:\n",
    "        raise RuntimeError(\"No images matched the size filter with target classes.\")\n",
    "\n",
    "    print(f\"  eligible images: {len(kept_images)}\")\n",
    "    samp = sample_images(kept_images, target_n)\n",
    "    ensure_dir(out_img_dir)\n",
    "\n",
    "    new_names = {}\n",
    "    for im in samp:\n",
    "        in_path = os.path.join(img_dir, im[\"file_name\"])\n",
    "        base = Path(im[\"file_name\"]).stem\n",
    "        if APPLY_WEATHER:\n",
    "            img = cv2.imread(in_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            weathers = choose_weathers()\n",
    "            if not weathers:\n",
    "                # edge case, treat as copy\n",
    "                out_name = f\"{base}.jpg\"\n",
    "                out_path = os.path.join(out_img_dir, out_name)\n",
    "                shutil.copyfile(in_path, out_path)\n",
    "                new_names[im[\"id\"]] = out_name\n",
    "            elif len(weathers) == 1:\n",
    "                which = weathers[0]\n",
    "                out_name = f\"{base}_{which}.jpg\"\n",
    "                out_path = os.path.join(out_img_dir, out_name)\n",
    "                out_img = weather_once(img, which)\n",
    "                cv2.imwrite(out_path, out_img)\n",
    "                new_names[im[\"id\"]] = out_name\n",
    "            else:\n",
    "                out_first_name = None\n",
    "                for idx, which in enumerate(weathers):\n",
    "                    out_name = f\"{base}_{which}.jpg\"\n",
    "                    out_path = os.path.join(out_img_dir, out_name)\n",
    "                    out_img = weather_once(img, which)\n",
    "                    cv2.imwrite(out_path, out_img)\n",
    "                    if idx == 0:\n",
    "                        out_first_name = out_name\n",
    "                new_names[im[\"id\"]] = out_first_name\n",
    "        else:\n",
    "            # weather off, copy original\n",
    "            out_name = f\"{base}.jpg\"\n",
    "            out_path = os.path.join(out_img_dir, out_name)\n",
    "            shutil.copyfile(in_path, out_path)\n",
    "            new_names[im[\"id\"]] = out_name\n",
    "\n",
    "    out_json = rewrite_json(coco, samp, anns_by_img, keep_cats, old2new, new_names)\n",
    "    ensure_dir(Path(out_json_path).parent)\n",
    "    with open(out_json_path, \"w\") as f:\n",
    "        json.dump(out_json, f)\n",
    "    print(f\"  -> wrote {len(out_json['images'])} images to {out_img_dir}\")\n",
    "    print(f\"  -> {out_json_path}\")\n",
    "    if len(out_json[\"annotations\"]) == 0:\n",
    "        print(\"  warning: zero annotations after filtering\")\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUT_ROOT)\n",
    "    process_split(TRAIN_IM_DIR, TRAIN_ANN_IN, OUT_TRAIN_IM, OUT_TRAIN_JS, TRAIN_TARGET)\n",
    "    process_split(VAL_IM_DIR,   VAL_ANN_IN,   OUT_VAL_IM,   OUT_VAL_JS,   VAL_TARGET)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather label tags added\n",
    "import os, json, random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "WEATHER_LABELS = (\"clear\", \"fog\", \"rain\", \"snow\")\n",
    "\n",
    "def with_weather_suffix(orig_name: str, tag: str) -> str:\n",
    "    \"\"\"'000123.jpg' + 'fog' -> '000123_fog.jpg'.\"\"\"\n",
    "    base = Path(orig_name).stem\n",
    "    return f\"{base}_{tag}.jpg\"\n",
    "\n",
    "def weather_from_filename(file_name: str) -> str:\n",
    "    \"\"\"Parse weather tag from filename; defaults to 'clear'.\"\"\"\n",
    "    tag = Path(file_name).stem.split(\"_\")[-1].lower()\n",
    "    return tag if tag in WEATHER_LABELS else \"clear\"\n",
    "\n",
    "\n",
    "# ========= CONFIG =========\n",
    "COCO_ROOT = \"/nas.dbms/asera/PROJECTS/DATASET/COCO\"  # adjust\n",
    "TRAIN_IM_DIR = f\"{COCO_ROOT}/images/train2017\"\n",
    "VAL_IM_DIR   = f\"{COCO_ROOT}/images/val2017\"\n",
    "TRAIN_ANN_IN = f\"{COCO_ROOT}/annotations/instances_train2017.json\"\n",
    "VAL_ANN_IN   = f\"{COCO_ROOT}/annotations/instances_val2017.json\"\n",
    "\n",
    "OUT_ROOT     = f\"{COCO_ROOT}/weather-mini-tag\"  # will be created\n",
    "OUT_TRAIN_IM = f\"{OUT_ROOT}/images/train2017_weather_tag_clear-2400k6c\"\n",
    "OUT_VAL_IM   = f\"{OUT_ROOT}/images/val2017_weather_tag_clear-500k6c\"\n",
    "OUT_TRAIN_JS = f\"{OUT_ROOT}/annotations/mini_train2017_weather_tag_clear-2400k6c.json\"\n",
    "OUT_VAL_JS   = f\"{OUT_ROOT}/annotations/mini_val2017_weather_tag_clear-500k6c.json\"\n",
    "\n",
    "\n",
    "# pick how many final images per split\n",
    "TRAIN_TARGET = 2400\n",
    "VAL_TARGET   = 500\n",
    "\n",
    "\n",
    "# size selection: \"all\", \"small\", \"medium\", \"large\"\n",
    "SIZE_FILTER = \"all\"   # set to \"all\" | \"small\" | \"medium\" | \"large\"\n",
    "\n",
    "# COCO size rules: small < 32^2, medium in [32^2, 96^2), large >= 96^2\n",
    "# or strict max side rule if USE_COCO_AREA=False\n",
    "USE_COCO_AREA = True\n",
    "AREA_SMALL_MAX  = 32 * 32\n",
    "AREA_MED_MAX    = 96 * 96\n",
    "MAX_SIDE_SMALL  = 48\n",
    "MAX_SIDE_MEDMAX = 96\n",
    "\n",
    "# keep only annotations that match SIZE_FILTER within selected images\n",
    "KEEP_ONLY_MATCHING_ANNS = True\n",
    "\n",
    "# weather settings\n",
    "APPLY_WEATHER = False   # master switch. False means no weather, images copied as-is\n",
    "APPLY_FOG  = False\n",
    "APPLY_RAIN = False\n",
    "APPLY_SNOW = False\n",
    "WEATHER_PER_IMAGE = 3   # 1 means pick one at random, 3 means generate fog+rain+snow\n",
    "\n",
    "# DAWN-like classes\n",
    "TARGET_CLASS_NAMES = [\"person\",\"bicycle\",\"car\",\"motorcycle\",\"bus\",\"truck\"]\n",
    "# Select all COCO classes without listing them one by one\n",
    "class _All:\n",
    "    def __contains__(self, _):\n",
    "        return True\n",
    "\n",
    "# TARGET_CLASS_NAMES = _All()  # means all 80 COCO classes\n",
    "\n",
    "# reproducibility\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# ========= WEATHER OPS =========\n",
    "def _gaussian_mask(h, w, sigma=0.35):\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    yy = (yy - h/2) / (sigma*h)\n",
    "    xx = (xx - w/2) / (sigma*w)\n",
    "    m = np.exp(-(xx**2 + yy**2))\n",
    "    m = (m - m.min()) / (m.max() - m.min() + 1e-8)\n",
    "    return m[..., None].astype(np.float32)\n",
    "\n",
    "def add_fog(img, strength=0.55):\n",
    "    blur = cv2.GaussianBlur(img, (0,0), sigmaX=max(3, int(0.02*max(img.shape[:2]))))\n",
    "    fog  = np.clip(blur + strength*255, 0, 255).astype(np.uint8)\n",
    "    mask = _gaussian_mask(img.shape[0], img.shape[1], sigma=0.38)\n",
    "    out  = (img*(1-mask) + fog*mask).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def add_rain(img, streaks=1100, alpha=0.20, angle_deg=18, length=(8,18)):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    ang = np.deg2rad(angle_deg)\n",
    "    c,s = np.cos(ang), np.sin(ang)\n",
    "    for _ in range(streaks):\n",
    "        L = np.random.randint(length[0], length[1]+1)\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        x2 = int(x + L*c); y2 = int(y + L*s)\n",
    "        cv2.line(overlay, (x,y), (x2,y2), (255,255,255), 1, cv2.LINE_AA)\n",
    "    overlay = cv2.blur(overlay, (3,3))\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def add_snow(img, flakes=2000, alpha=0.30):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    for _ in range(flakes):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        r = np.random.randint(1,3)\n",
    "        cv2.circle(overlay, (x,y), r, (255,255,255), -1, cv2.LINE_AA)\n",
    "    overlay = cv2.GaussianBlur(overlay, (3,3), 0)\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def weather_once(img, which):\n",
    "    if which == \"fog\":  return add_fog(img)\n",
    "    if which == \"rain\": return add_rain(img)\n",
    "    if which == \"snow\": return add_snow(img)\n",
    "    return img\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def load_json(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def ensure_dir(p):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filter_to_targets(coco):\n",
    "    keep_cat = [c for c in coco[\"categories\"] if c[\"name\"] in TARGET_CLASS_NAMES]\n",
    "    oldid2new = {c[\"id\"]: i+1 for i,c in enumerate(keep_cat)}\n",
    "    for i,c in enumerate(keep_cat):\n",
    "        c[\"id\"] = i+1\n",
    "    return keep_cat, oldid2new\n",
    "\n",
    "def coco_size_bucket(area):\n",
    "    if area < AREA_SMALL_MAX:\n",
    "        return \"small\"\n",
    "    if area < AREA_MED_MAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def side_size_bucket(w, h):\n",
    "    mx = max(w, h)\n",
    "    if mx < MAX_SIDE_SMALL:\n",
    "        return \"small\"\n",
    "    if mx < MAX_SIDE_MEDMAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def ann_size_bucket(ann):\n",
    "    x,y,w,h = ann[\"bbox\"]\n",
    "    area = ann.get(\"area\", w*h)\n",
    "    return coco_size_bucket(area) if USE_COCO_AREA else side_size_bucket(w, h)\n",
    "\n",
    "def matches_size_filter(size_name):\n",
    "    if SIZE_FILTER == \"all\":\n",
    "        return True\n",
    "    return size_name == SIZE_FILTER\n",
    "\n",
    "def choose_weathers():\n",
    "    if not APPLY_WEATHER:\n",
    "        return []\n",
    "    opts = []\n",
    "    if APPLY_FOG:  opts.append(\"fog\")\n",
    "    if APPLY_RAIN: opts.append(\"rain\")\n",
    "    if APPLY_SNOW: opts.append(\"snow\")\n",
    "    if not opts:\n",
    "        return []\n",
    "    if WEATHER_PER_IMAGE == 3:\n",
    "        return opts\n",
    "    return [random.choice(opts)]\n",
    "\n",
    "def sample_images(kept_images, target_n):\n",
    "    if len(kept_images) <= target_n:\n",
    "        return kept_images\n",
    "    return random.sample(kept_images, target_n)\n",
    "\n",
    "# ========= CORE SELECTION =========\n",
    "def collect_images_by_size(coco, img_dir):\n",
    "    keep_cats, old2new = filter_to_targets(coco)\n",
    "    # group anns by image, only target cats\n",
    "    anns_by_img_all = defaultdict(list)\n",
    "    for a in coco[\"annotations\"]:\n",
    "        if a[\"category_id\"] in old2new:\n",
    "            anns_by_img_all[a[\"image_id\"]].append(a)\n",
    "\n",
    "    # keep images that have at least one annotation matching SIZE_FILTER\n",
    "    kept_images = []\n",
    "    matched_anns_by_img = defaultdict(list)\n",
    "    for img in coco[\"images\"]:\n",
    "        iid = img[\"id\"]\n",
    "        if iid not in anns_by_img_all:\n",
    "            continue\n",
    "        p = os.path.join(img_dir, img[\"file_name\"])\n",
    "        if not os.path.isfile(p):\n",
    "            continue\n",
    "\n",
    "        anns = anns_by_img_all[iid]\n",
    "        has_match = False\n",
    "        tmp = []\n",
    "        for a in anns:\n",
    "            sz = ann_size_bucket(a)\n",
    "            if matches_size_filter(sz):\n",
    "                has_match = True\n",
    "                tmp.append(a)\n",
    "\n",
    "        if SIZE_FILTER == \"all\":\n",
    "            # any target class is fine\n",
    "            if len(anns) > 0:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = anns\n",
    "        else:\n",
    "            if has_match:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = tmp if KEEP_ONLY_MATCHING_ANNS else anns\n",
    "\n",
    "    return kept_images, matched_anns_by_img, keep_cats, old2new\n",
    "\n",
    "# ========= JSON REWRITE =========\n",
    "def rewrite_json(coco, variants, anns_by_img, keep_cats, old2new):\n",
    "    \"\"\"\n",
    "    variants: list of dicts with keys:\n",
    "      {'orig_id', 'new_id', 'file_name', 'width', 'height', 'weather'}\n",
    "    \"\"\"\n",
    "    out_imgs = []\n",
    "    out_anns = []\n",
    "    nid = 1\n",
    "\n",
    "    for rec in variants:\n",
    "        out_imgs.append({\n",
    "            \"id\": rec[\"new_id\"],\n",
    "            \"file_name\": rec[\"file_name\"],\n",
    "            \"width\": rec[\"width\"],\n",
    "            \"height\": rec[\"height\"],\n",
    "            # custom field; most COCO readers will ignore it unless you use it\n",
    "            \"weather\": rec[\"weather\"]\n",
    "        })\n",
    "\n",
    "        for a in anns_by_img[rec[\"orig_id\"]]:\n",
    "            cid_new = old2new.get(a[\"category_id\"])\n",
    "            if not cid_new:\n",
    "                continue\n",
    "            x, y, bw, bh = a[\"bbox\"]\n",
    "            area = a.get(\"area\", bw * bh)\n",
    "            out_anns.append({\n",
    "                \"id\": nid,\n",
    "                \"image_id\": rec[\"new_id\"],\n",
    "                \"category_id\": cid_new,\n",
    "                \"bbox\": [float(x), float(y), float(bw), float(bh)],\n",
    "                \"area\": float(area),\n",
    "                \"iscrowd\": int(a.get(\"iscrowd\", 0)),\n",
    "            })\n",
    "            nid += 1\n",
    "\n",
    "    # drop images that ended up annotation-less\n",
    "    valid_ids = {a[\"image_id\"] for a in out_anns}\n",
    "    out_imgs = [im for im in out_imgs if im[\"id\"] in valid_ids]\n",
    "\n",
    "    return {\n",
    "        \"info\": coco.get(\"info\", {\"description\": \"COCO size-filtered mini with weather tags\"}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"images\": out_imgs,\n",
    "        \"annotations\": out_anns,\n",
    "        \"categories\": keep_cats\n",
    "    }\n",
    "\n",
    "# ========= PIPELINE =========\n",
    "def process_split(img_dir, ann_in, out_img_dir, out_json_path, target_n):\n",
    "    print(f\"[SPLIT] {img_dir} size={SIZE_FILTER} weather={'on' if APPLY_WEATHER else 'off'}\")\n",
    "    coco = load_json(ann_in)\n",
    "    kept_images, anns_by_img, keep_cats, old2new = collect_images_by_size(coco, img_dir)\n",
    "    if not kept_images:\n",
    "        raise RuntimeError(\"No images matched the size filter with target classes.\")\n",
    "\n",
    "    print(f\"  eligible images: {len(kept_images)}\")\n",
    "    samp = sample_images(kept_images, target_n)\n",
    "    ensure_dir(out_img_dir)\n",
    "\n",
    "    variants = []\n",
    "    next_img_id = 1  # re-id images in the new JSON\n",
    "\n",
    "    for im in samp:\n",
    "        in_path = os.path.join(img_dir, im[\"file_name\"])\n",
    "        base = Path(im[\"file_name\"]).stem\n",
    "\n",
    "        if APPLY_WEATHER:\n",
    "            img = cv2.imread(in_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            weathers = choose_weathers() or [\"clear\"]  # safety\n",
    "\n",
    "            for which in weathers:\n",
    "                out_name = with_weather_suffix(im[\"file_name\"], which)\n",
    "                out_path = os.path.join(out_img_dir, out_name)\n",
    "                if which == \"clear\":\n",
    "                    shutil.copyfile(in_path, out_path)\n",
    "                else:\n",
    "                    out_img = weather_once(img, which)\n",
    "                    cv2.imwrite(out_path, out_img)\n",
    "\n",
    "                variants.append({\n",
    "                    \"orig_id\": im[\"id\"],\n",
    "                    \"new_id\": next_img_id,\n",
    "                    \"file_name\": out_name,\n",
    "                    \"width\": im.get(\"width\"),\n",
    "                    \"height\": im.get(\"height\"),\n",
    "                    \"weather\": which\n",
    "                })\n",
    "                next_img_id += 1\n",
    "\n",
    "        else:\n",
    "            # weather off: still tag filenames as _clear so you can FiLM by label\n",
    "            out_name = with_weather_suffix(im[\"file_name\"], \"clear\")\n",
    "            out_path = os.path.join(out_img_dir, out_name)\n",
    "            shutil.copyfile(in_path, out_path)\n",
    "\n",
    "            variants.append({\n",
    "                \"orig_id\": im[\"id\"],\n",
    "                \"new_id\": next_img_id,\n",
    "                \"file_name\": out_name,\n",
    "                \"width\": im.get(\"width\"),\n",
    "                \"height\": im.get(\"height\"),\n",
    "                \"weather\": \"clear\"\n",
    "            })\n",
    "            next_img_id += 1\n",
    "\n",
    "    out_json = rewrite_json(coco, variants, anns_by_img, keep_cats, old2new)\n",
    "    ensure_dir(Path(out_json_path).parent)\n",
    "    with open(out_json_path, \"w\") as f:\n",
    "        json.dump(out_json, f)\n",
    "    print(f\"  -> wrote {len(out_json['images'])} images to {out_img_dir}\")\n",
    "    print(f\"  -> {out_json_path}\")\n",
    "    if len(out_json[\"annotations\"]) == 0:\n",
    "        print(\"  warning: zero annotations after filtering\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUT_ROOT)\n",
    "    process_split(TRAIN_IM_DIR, TRAIN_ANN_IN, OUT_TRAIN_IM, OUT_TRAIN_JS, TRAIN_TARGET)\n",
    "    process_split(VAL_IM_DIR,   VAL_ANN_IN,   OUT_VAL_IM,   OUT_VAL_JS,   VAL_TARGET)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to remove a class with 0 objects\n",
    "import os, json, random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "WEATHER_LABELS = (\"clear\", \"fog\", \"rain\", \"snow\")\n",
    "\n",
    "# remove any category that ends up with 0 annotations after filtering/sampling\n",
    "REMOVE_EMPTY_CLASSES = True\n",
    "\n",
    "\n",
    "def with_weather_suffix(orig_name: str, tag: str) -> str:\n",
    "    \"\"\"'000123.jpg' + 'fog' -> '000123_fog.jpg'.\"\"\"\n",
    "    base = Path(orig_name).stem\n",
    "    return f\"{base}_{tag}.jpg\"\n",
    "\n",
    "def weather_from_filename(file_name: str) -> str:\n",
    "    \"\"\"Parse weather tag from filename; defaults to 'clear'.\"\"\"\n",
    "    tag = Path(file_name).stem.split(\"_\")[-1].lower()\n",
    "    return tag if tag in WEATHER_LABELS else \"clear\"\n",
    "\n",
    "\n",
    "# ========= CONFIG =========\n",
    "COCO_ROOT = \"/nas.dbms/asera/PROJECTS/DATASET/ACDC-1\"  # adjust\n",
    "TRAIN_IM_DIR = f\"{COCO_ROOT}/train\"\n",
    "VAL_IM_DIR   = f\"{COCO_ROOT}/valid\"\n",
    "TRAIN_ANN_IN = f\"{COCO_ROOT}/train/_annotations.coco.json\"\n",
    "VAL_ANN_IN   = f\"{COCO_ROOT}/valid/_annotations.coco.json\"\n",
    "\n",
    "OUT_ROOT     = f\"{COCO_ROOT}/ACDC-1-NEW\"  # will be created\n",
    "OUT_TRAIN_IM = f\"{OUT_ROOT}/images/train\"\n",
    "OUT_VAL_IM   = f\"{OUT_ROOT}/images/val\"\n",
    "OUT_TRAIN_JS = f\"{OUT_ROOT}/annotations/mini_train.json\"\n",
    "OUT_VAL_JS   = f\"{OUT_ROOT}/annotations/mini_val.json\"\n",
    "\n",
    "\n",
    "# pick how many final images per split\n",
    "TRAIN_TARGET = 3000\n",
    "VAL_TARGET   = 500\n",
    "\n",
    "\n",
    "# size selection: \"all\", \"small\", \"medium\", \"large\"\n",
    "SIZE_FILTER = \"all\"   # set to \"all\" | \"small\" | \"medium\" | \"large\"\n",
    "\n",
    "# COCO size rules: small < 32^2, medium in [32^2, 96^2), large >= 96^2\n",
    "# or strict max side rule if USE_COCO_AREA=False\n",
    "USE_COCO_AREA = True\n",
    "AREA_SMALL_MAX  = 32 * 32\n",
    "AREA_MED_MAX    = 96 * 96\n",
    "MAX_SIDE_SMALL  = 48\n",
    "MAX_SIDE_MEDMAX = 96\n",
    "\n",
    "# keep only annotations that match SIZE_FILTER within selected images\n",
    "KEEP_ONLY_MATCHING_ANNS = True\n",
    "\n",
    "# weather settings\n",
    "APPLY_WEATHER = False   # master switch. False means no weather, images copied as-is\n",
    "APPLY_FOG  = False\n",
    "APPLY_RAIN = False\n",
    "APPLY_SNOW = False\n",
    "WEATHER_PER_IMAGE = 3   # 1 means pick one at random, 3 means generate fog+rain+snow\n",
    "\n",
    "# DAWN-like classes\n",
    "TARGET_CLASS_NAMES = [\"person\",\"bicycle\",\"car\",\"motorcycle\",\"bus\",\"truck\"]\n",
    "# TARGET_CLASS_NAMES = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]  # DAWN-1 classes\n",
    "# Select all COCO classes without listing them one by one\n",
    "class _All:\n",
    "    def __contains__(self, _):\n",
    "        return True\n",
    "\n",
    "# TARGET_CLASS_NAMES = _All()  # means all 80 COCO classes\n",
    "\n",
    "# reproducibility\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# ========= WEATHER OPS =========\n",
    "def _gaussian_mask(h, w, sigma=0.35):\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    yy = (yy - h/2) / (sigma*h)\n",
    "    xx = (xx - w/2) / (sigma*w)\n",
    "    m = np.exp(-(xx**2 + yy**2))\n",
    "    m = (m - m.min()) / (m.max() - m.min() + 1e-8)\n",
    "    return m[..., None].astype(np.float32)\n",
    "\n",
    "def add_fog(img, strength=0.55):\n",
    "    blur = cv2.GaussianBlur(img, (0,0), sigmaX=max(3, int(0.02*max(img.shape[:2]))))\n",
    "    fog  = np.clip(blur + strength*255, 0, 255).astype(np.uint8)\n",
    "    mask = _gaussian_mask(img.shape[0], img.shape[1], sigma=0.38)\n",
    "    out  = (img*(1-mask) + fog*mask).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def add_rain(img, streaks=1100, alpha=0.20, angle_deg=18, length=(8,18)):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    ang = np.deg2rad(angle_deg)\n",
    "    c,s = np.cos(ang), np.sin(ang)\n",
    "    for _ in range(streaks):\n",
    "        L = np.random.randint(length[0], length[1]+1)\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        x2 = int(x + L*c); y2 = int(y + L*s)\n",
    "        cv2.line(overlay, (x,y), (x2,y2), (255,255,255), 1, cv2.LINE_AA)\n",
    "    overlay = cv2.blur(overlay, (3,3))\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def add_snow(img, flakes=2000, alpha=0.30):\n",
    "    h,w = img.shape[:2]\n",
    "    overlay = img.copy()\n",
    "    for _ in range(flakes):\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        r = np.random.randint(1,3)\n",
    "        cv2.circle(overlay, (x,y), r, (255,255,255), -1, cv2.LINE_AA)\n",
    "    overlay = cv2.GaussianBlur(overlay, (3,3), 0)\n",
    "    return cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "\n",
    "def weather_once(img, which):\n",
    "    if which == \"fog\":  return add_fog(img)\n",
    "    if which == \"rain\": return add_rain(img)\n",
    "    if which == \"snow\": return add_snow(img)\n",
    "    return img\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def load_json(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def ensure_dir(p):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def filter_to_targets(coco):\n",
    "    keep_cat = [c for c in coco[\"categories\"] if c[\"name\"] in TARGET_CLASS_NAMES]\n",
    "    oldid2new = {c[\"id\"]: i+1 for i,c in enumerate(keep_cat)}\n",
    "    for i,c in enumerate(keep_cat):\n",
    "        c[\"id\"] = i+1\n",
    "    return keep_cat, oldid2new\n",
    "\n",
    "def coco_size_bucket(area):\n",
    "    if area < AREA_SMALL_MAX:\n",
    "        return \"small\"\n",
    "    if area < AREA_MED_MAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def side_size_bucket(w, h):\n",
    "    mx = max(w, h)\n",
    "    if mx < MAX_SIDE_SMALL:\n",
    "        return \"small\"\n",
    "    if mx < MAX_SIDE_MEDMAX:\n",
    "        return \"medium\"\n",
    "    return \"large\"\n",
    "\n",
    "def ann_size_bucket(ann):\n",
    "    x,y,w,h = ann[\"bbox\"]\n",
    "    area = ann.get(\"area\", w*h)\n",
    "    return coco_size_bucket(area) if USE_COCO_AREA else side_size_bucket(w, h)\n",
    "\n",
    "def matches_size_filter(size_name):\n",
    "    if SIZE_FILTER == \"all\":\n",
    "        return True\n",
    "    return size_name == SIZE_FILTER\n",
    "\n",
    "def choose_weathers():\n",
    "    if not APPLY_WEATHER:\n",
    "        return []\n",
    "    opts = []\n",
    "    if APPLY_FOG:  opts.append(\"fog\")\n",
    "    if APPLY_RAIN: opts.append(\"rain\")\n",
    "    if APPLY_SNOW: opts.append(\"snow\")\n",
    "    if not opts:\n",
    "        return []\n",
    "    if WEATHER_PER_IMAGE == 3:\n",
    "        return opts\n",
    "    return [random.choice(opts)]\n",
    "\n",
    "def sample_images(kept_images, target_n):\n",
    "    if len(kept_images) <= target_n:\n",
    "        return kept_images\n",
    "    return random.sample(kept_images, target_n)\n",
    "\n",
    "# ========= CORE SELECTION =========\n",
    "def collect_images_by_size(coco, img_dir):\n",
    "    keep_cats, old2new = filter_to_targets(coco)\n",
    "    # group anns by image, only target cats\n",
    "    anns_by_img_all = defaultdict(list)\n",
    "    for a in coco[\"annotations\"]:\n",
    "        if a[\"category_id\"] in old2new:\n",
    "            anns_by_img_all[a[\"image_id\"]].append(a)\n",
    "\n",
    "    # keep images that have at least one annotation matching SIZE_FILTER\n",
    "    kept_images = []\n",
    "    matched_anns_by_img = defaultdict(list)\n",
    "    for img in coco[\"images\"]:\n",
    "        iid = img[\"id\"]\n",
    "        if iid not in anns_by_img_all:\n",
    "            continue\n",
    "        p = os.path.join(img_dir, img[\"file_name\"])\n",
    "        if not os.path.isfile(p):\n",
    "            continue\n",
    "\n",
    "        anns = anns_by_img_all[iid]\n",
    "        has_match = False\n",
    "        tmp = []\n",
    "        for a in anns:\n",
    "            sz = ann_size_bucket(a)\n",
    "            if matches_size_filter(sz):\n",
    "                has_match = True\n",
    "                tmp.append(a)\n",
    "\n",
    "        if SIZE_FILTER == \"all\":\n",
    "            # any target class is fine\n",
    "            if len(anns) > 0:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = anns\n",
    "        else:\n",
    "            if has_match:\n",
    "                kept_images.append(img)\n",
    "                matched_anns_by_img[iid] = tmp if KEEP_ONLY_MATCHING_ANNS else anns\n",
    "\n",
    "    return kept_images, matched_anns_by_img, keep_cats, old2new\n",
    "\n",
    "# ========= JSON REWRITE =========\n",
    "def rewrite_json(coco, kept_images, anns_by_img, keep_cats, old2new, new_filenames):\n",
    "    \"\"\"\n",
    "    Builds a new COCO JSON:\n",
    "      - remaps categories to 1..K\n",
    "      - optionally removes categories with 0 instances\n",
    "      - drops images with no remaining annotations\n",
    "    \"\"\"\n",
    "    keep_img_ids = {im[\"id\"] for im in kept_images}\n",
    "\n",
    "    # stage 1: build image entries with possibly new filenames\n",
    "    out_imgs = []\n",
    "    for im in kept_images:\n",
    "        new_file = new_filenames.get(im[\"id\"], im[\"file_name\"])\n",
    "        out_imgs.append({\n",
    "            \"id\": im[\"id\"],\n",
    "            \"file_name\": new_file,\n",
    "            \"width\": im.get(\"width\"),\n",
    "            \"height\": im.get(\"height\")\n",
    "        })\n",
    "\n",
    "    # stage 2: count instances per *new* category id (after TARGET_CLASS_NAMES filter)\n",
    "    # counts are computed on the anns that survived SIZE_FILTER and exist in anns_by_img\n",
    "    cat_counts_newid = defaultdict(int)\n",
    "    for iid in keep_img_ids:\n",
    "        for a in anns_by_img[iid]:\n",
    "            cid_new = old2new.get(a[\"category_id\"])\n",
    "            if cid_new is not None:\n",
    "                cat_counts_newid[cid_new] += 1\n",
    "\n",
    "    # stage 3: select category ids to keep\n",
    "    if REMOVE_EMPTY_CLASSES:\n",
    "        kept_new_cat_ids = sorted([k for k, v in cat_counts_newid.items() if v > 0])\n",
    "    else:\n",
    "        # keep everything that was in keep_cats regardless of count\n",
    "        kept_new_cat_ids = sorted([i + 1 for i in range(len(keep_cats))])\n",
    "\n",
    "    # build mapping from current new-id -> final compact id 1..K\n",
    "    new_to_final = {cid_new: i + 1 for i, cid_new in enumerate(kept_new_cat_ids)}\n",
    "    kept_new_cat_ids_set = set(kept_new_cat_ids)\n",
    "\n",
    "    # stage 4: build categories list with compact ids\n",
    "    out_cats = []\n",
    "    # keep_cats already had ids reassigned to 1..len(keep_cats) in filter_to_targets()\n",
    "    # we must only keep those whose id is in kept_new_cat_ids, and reassign their id to new_to_final\n",
    "    for c in keep_cats:\n",
    "        old_new_id = c[\"id\"]\n",
    "        if old_new_id in kept_new_cat_ids_set:\n",
    "            out_cats.append({\n",
    "                \"id\": new_to_final[old_new_id],\n",
    "                \"name\": c[\"name\"],\n",
    "                \"supercategory\": c.get(\"supercategory\", \"\")\n",
    "            })\n",
    "\n",
    "    # stage 5: build annotations with compact category ids\n",
    "    out_anns = []\n",
    "    nid = 1\n",
    "    for iid in keep_img_ids:\n",
    "        for a in anns_by_img[iid]:\n",
    "            cid_new = old2new.get(a[\"category_id\"])\n",
    "            if cid_new is None:\n",
    "                continue\n",
    "            if cid_new not in kept_new_cat_ids_set:\n",
    "                continue  # category removed due to zero instances\n",
    "            x, y, w, h = a[\"bbox\"]\n",
    "            out_anns.append({\n",
    "                \"id\": nid,\n",
    "                \"image_id\": iid,\n",
    "                \"category_id\": new_to_final[cid_new],\n",
    "                \"bbox\": [float(x), float(y), float(w), float(h)],\n",
    "                \"area\": float(a.get(\"area\", w * h)),\n",
    "                \"iscrowd\": int(a.get(\"iscrowd\", 0))\n",
    "            })\n",
    "            nid += 1\n",
    "\n",
    "    # stage 6: drop images that lost all annotations after category removal\n",
    "    valid_ids = {a[\"image_id\"] for a in out_anns}\n",
    "    out_imgs = [im for im in out_imgs if im[\"id\"] in valid_ids]\n",
    "\n",
    "    # optional: simple console summary\n",
    "    if REMOVE_EMPTY_CLASSES:\n",
    "        removed = [c[\"name\"] for c in keep_cats if c[\"id\"] not in kept_new_cat_ids_set]\n",
    "        if removed:\n",
    "            print(f\"  removed empty classes: {removed}\")\n",
    "\n",
    "    return {\n",
    "        \"info\": coco.get(\"info\", {\"description\": \"COCO size-filtered mini\"}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"images\": out_imgs,\n",
    "        \"annotations\": out_anns,\n",
    "        \"categories\": out_cats\n",
    "    }\n",
    "\n",
    "\n",
    "# ========= PIPELINE =========\n",
    "def process_split(img_dir, ann_in, out_img_dir, out_json_path, target_n):\n",
    "    print(f\"[SPLIT] {img_dir} size={SIZE_FILTER} weather={'on' if APPLY_WEATHER else 'off'}\")\n",
    "    coco = load_json(ann_in)\n",
    "    kept_images, anns_by_img, keep_cats, old2new = collect_images_by_size(coco, img_dir)\n",
    "    if not kept_images:\n",
    "        raise RuntimeError(\"No images matched the size filter with target classes.\")\n",
    "\n",
    "    print(f\"  eligible images: {len(kept_images)}\")\n",
    "    samp = sample_images(kept_images, target_n)\n",
    "    ensure_dir(out_img_dir)\n",
    "\n",
    "    new_names = {}\n",
    "    for im in samp:\n",
    "        in_path = os.path.join(img_dir, im[\"file_name\"])\n",
    "        base = Path(im[\"file_name\"]).stem\n",
    "        if APPLY_WEATHER:\n",
    "            img = cv2.imread(in_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            weathers = choose_weathers()\n",
    "            if not weathers:\n",
    "                # edge case, treat as copy\n",
    "                out_name = f\"{base}.jpg\"\n",
    "                out_path = os.path.join(out_img_dir, out_name)\n",
    "                shutil.copyfile(in_path, out_path)\n",
    "                new_names[im[\"id\"]] = out_name\n",
    "            elif len(weathers) == 1:\n",
    "                which = weathers[0]\n",
    "                out_name = f\"{base}_{which}.jpg\"\n",
    "                out_path = os.path.join(out_img_dir, out_name)\n",
    "                out_img = weather_once(img, which)\n",
    "                cv2.imwrite(out_path, out_img)\n",
    "                new_names[im[\"id\"]] = out_name\n",
    "            else:\n",
    "                out_first_name = None\n",
    "                for idx, which in enumerate(weathers):\n",
    "                    out_name = f\"{base}_{which}.jpg\"\n",
    "                    out_path = os.path.join(out_img_dir, out_name)\n",
    "                    out_img = weather_once(img, which)\n",
    "                    cv2.imwrite(out_path, out_img)\n",
    "                    if idx == 0:\n",
    "                        out_first_name = out_name\n",
    "                new_names[im[\"id\"]] = out_first_name\n",
    "        else:\n",
    "            # weather off, copy original\n",
    "            out_name = f\"{base}.jpg\"\n",
    "            out_path = os.path.join(out_img_dir, out_name)\n",
    "            shutil.copyfile(in_path, out_path)\n",
    "            new_names[im[\"id\"]] = out_name\n",
    "\n",
    "    out_json = rewrite_json(coco, samp, anns_by_img, keep_cats, old2new, new_names)\n",
    "    ensure_dir(Path(out_json_path).parent)\n",
    "    with open(out_json_path, \"w\") as f:\n",
    "        json.dump(out_json, f)\n",
    "    print(f\"  -> wrote {len(out_json['images'])} images to {out_img_dir}\")\n",
    "    print(f\"  -> {out_json_path}\")\n",
    "    if len(out_json[\"annotations\"]) == 0:\n",
    "        print(\"  warning: zero annotations after filtering\")\n",
    "\n",
    "def main():\n",
    "    ensure_dir(OUT_ROOT)\n",
    "    process_split(TRAIN_IM_DIR, TRAIN_ANN_IN, OUT_TRAIN_IM, OUT_TRAIN_JS, TRAIN_TARGET)\n",
    "    process_split(VAL_IM_DIR,   VAL_ANN_IN,   OUT_VAL_IM,   OUT_VAL_JS,   VAL_TARGET)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA_11.6_env-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
