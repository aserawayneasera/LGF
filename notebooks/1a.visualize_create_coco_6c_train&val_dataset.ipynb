{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the dataset with small, medium and large objects\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def count_class_instances(coco, category_ids):\n",
    "    # Count instances for each category ID\n",
    "    class_counts = {cat_id: 0 for cat_id in category_ids}\n",
    "    for ann in coco.anns.values():\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id in class_counts:\n",
    "            class_counts[cat_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "def count_images_per_class(coco, category_ids):\n",
    "    # Count images per class\n",
    "    image_counts = {cat_id: set() for cat_id in category_ids}\n",
    "    for ann in coco.anns.values():\n",
    "        cat_id = ann['category_id']\n",
    "        image_id = ann['image_id']\n",
    "        if cat_id in image_counts:\n",
    "            image_counts[cat_id].add(image_id)\n",
    "    # Convert sets to counts\n",
    "    return {cat_id: len(images) for cat_id, images in image_counts.items()}\n",
    "\n",
    "def count_object_sizes(coco):\n",
    "    # Count small, medium, and large objects\n",
    "    small, medium, large = 0, 0, 0\n",
    "    for ann in coco.anns.values():\n",
    "        _, _, width, height = ann['bbox']\n",
    "        area = width * height\n",
    "\n",
    "        if area < 32**2:\n",
    "            small += 1\n",
    "        elif 32**2 <= area < 96**2:\n",
    "            medium += 1\n",
    "        else:\n",
    "            large += 1\n",
    "\n",
    "    return small, medium, large\n",
    "\n",
    "def plot_class_distribution(class_counts, coco):\n",
    "    # Convert category IDs to names for plotting\n",
    "    category_names = [coco.cats[cat_id]['name'] for cat_id in class_counts.keys()]\n",
    "    counts = list(class_counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(category_names, counts, color='skyblue')\n",
    "    plt.xlabel('Number of Instances')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show()\n",
    "\n",
    "def plot_size_distribution(size_counts, dataset_type):\n",
    "    sizes = ['Small', 'Medium', 'Large']\n",
    "    counts = size_counts\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(sizes, counts, color=['lightcoral', 'gold', 'lightgreen'])\n",
    "    plt.xlabel('Object Size')\n",
    "    plt.ylabel('Number of Objects')\n",
    "    plt.title(f'Object Size Distribution ({dataset_type} Dataset)')\n",
    "    plt.show()\n",
    "\n",
    "# Paths to your annotation files\n",
    "# train_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/mini-annotations/mini_train2017-8k-5c.json'\n",
    "# val_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/mini-annotations/mini_val2017-2k-5c.json'\n",
    "\n",
    "# train_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/annotations/mini_train2017_non_weather-2400k6c.json'\n",
    "# val_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/non_weather-mini/annotations/mini_val2017_non_weather-500k6c.json'\n",
    "\n",
    "# train_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/annotations/mini_train2017_weather-2400k6c.json'\n",
    "# val_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/weather-mini/annotations/mini_val2017_weather-500k6c.json'\n",
    "train_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/annotations/mini_train.json'\n",
    "val_annotation_file = '/nas.dbms/asera/PROJECTS/DATASET/ACDC-1/ACDC-1-NEW/annotations/mini_val.json'\n",
    "\n",
    "\n",
    "# Initialize COCO API for both train and validation sets\n",
    "coco_train = COCO(train_annotation_file)\n",
    "coco_val = COCO(val_annotation_file)\n",
    "\n",
    "# Get category IDs from the training dataset\n",
    "category_ids = coco_train.getCatIds()\n",
    "\n",
    "# Count instances for training and validation sets\n",
    "train_class_counts = count_class_instances(coco_train, category_ids)\n",
    "val_class_counts = count_class_instances(coco_val, category_ids)\n",
    "\n",
    "# Count images per class for training and validation sets\n",
    "train_image_counts = count_images_per_class(coco_train, category_ids)\n",
    "val_image_counts = count_images_per_class(coco_val, category_ids)\n",
    "\n",
    "# Count object sizes for training and validation sets\n",
    "train_size_counts = count_object_sizes(coco_train)\n",
    "val_size_counts = count_object_sizes(coco_val)\n",
    "\n",
    "# Total image count\n",
    "total_train_images = len(coco_train.imgs)\n",
    "total_val_images = len(coco_val.imgs)\n",
    "\n",
    "# Plot distributions for training and validation sets\n",
    "print(\"Training Set Class Distribution:\")\n",
    "plot_class_distribution(train_class_counts, coco_train)\n",
    "print(\"Training Set Object Size Distribution:\")\n",
    "plot_size_distribution(train_size_counts, \"Training\")\n",
    "\n",
    "print(\"Validation Set Class Distribution:\")\n",
    "plot_class_distribution(val_class_counts, coco_val)\n",
    "print(\"Validation Set Object Size Distribution:\")\n",
    "plot_size_distribution(val_size_counts, \"Validation\")\n",
    "\n",
    "# Print counts for object sizes\n",
    "print(\"\\nTraining Set Object Size Counts:\")\n",
    "print(f\"Small: {train_size_counts[0]}, Medium: {train_size_counts[1]}, Large: {train_size_counts[2]}\")\n",
    "\n",
    "print(\"\\nValidation Set Object Size Counts:\")\n",
    "print(f\"Small: {val_size_counts[0]}, Medium: {val_size_counts[1]}, Large: {val_size_counts[2]}\")\n",
    "\n",
    "# Print counts for images per class\n",
    "print(\"\\nTraining Set Images per Class:\")\n",
    "for cat_id, count in train_image_counts.items():\n",
    "    print(f\"{coco_train.cats[cat_id]['name']}: {count}\")\n",
    "\n",
    "print(\"\\nValidation Set Images per Class:\")\n",
    "for cat_id, count in val_image_counts.items():\n",
    "    print(f\"{coco_val.cats[cat_id]['name']}: {count}\")\n",
    "\n",
    "# Print total image counts\n",
    "print(f\"\\nTotal Training Images: {total_train_images}\")\n",
    "print(f\"Total Validation Images: {total_val_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training dataset ONLY Randomly selected\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Path to the original COCO annotations\n",
    "original_ann_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/annotations/instances_train2017.json'\n",
    "\n",
    "\n",
    "# # MacBook Air\n",
    "# original_ann_file = '/mnt/localssd/coco2017/annotations/instances_train2017.json'\n",
    "\n",
    "# Parameters for customization\n",
    "num_images = 4000  # Specify the number of images for training (e.g., 100 images)\n",
    "selected_classes = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']  # Specify category names to include, leave empty for all classes (e.g., ['person', 'car'])\n",
    "\n",
    "\n",
    "# Load the original annotations\n",
    "with open(original_ann_file, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Filter images and annotations by selected classes if specified\n",
    "if selected_classes:\n",
    "    # Get category IDs for the selected classes\n",
    "    category_ids = {cat['id'] for cat in coco_data['categories'] if cat['name'] in selected_classes}\n",
    "\n",
    "    # Filter annotations by category IDs\n",
    "    filtered_annotations = [ann for ann in coco_data['annotations'] if ann['category_id'] in category_ids]\n",
    "\n",
    "    # Get image IDs for the filtered annotations\n",
    "    image_ids = {ann['image_id'] for ann in filtered_annotations}\n",
    "\n",
    "    # Filter images based on these image IDs\n",
    "    filtered_images = [img for img in coco_data['images'] if img['id'] in image_ids]\n",
    "else:\n",
    "    # Use all images and annotations if no classes are specified\n",
    "    filtered_images = coco_data['images']\n",
    "    filtered_annotations = coco_data['annotations']\n",
    "\n",
    "# Shuffle the filtered images randomly\n",
    "random.shuffle(filtered_images)\n",
    "\n",
    "# Limit the number of images to the specified value\n",
    "train_images = filtered_images[:num_images]\n",
    "\n",
    "# Filter annotations for the selected images\n",
    "def filter_annotations(images, annotations):\n",
    "    image_ids = {img['id'] for img in images}\n",
    "    return [ann for ann in annotations if ann['image_id'] in image_ids]\n",
    "\n",
    "train_annotations = filter_annotations(train_images, filtered_annotations)\n",
    "\n",
    "# Create the new JSON structure for training\n",
    "train_data = {\n",
    "    'images': train_images,\n",
    "    'annotations': train_annotations,\n",
    "    'categories': coco_data['categories']\n",
    "}\n",
    "\n",
    "# Save the new JSON file\n",
    "output_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/mini-annotations/mini_train2017-4k-5c.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "print(f\"Training images created with {len(train_images)} images.\")\n",
    "if selected_classes:\n",
    "    print(f\"Filtered by classes: {selected_classes}\")\n",
    "else:\n",
    "    print(\"All classes included.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbaa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation dataset ONLY Randomly selected\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Path to the original COCO annotations\n",
    "original_ann_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/annotations/instances_val2017.json'\n",
    "\n",
    "# # MacBook Air\n",
    "# original_ann_file = '/mnt/localssd/coco2017/annotations/instances_val2017.json'\n",
    "\n",
    "\n",
    "# Parameters for customization\n",
    "num_images = 2000  # Specify the number of images for validation (e.g., 100 images)\n",
    "selected_classes = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']  # Specify category names to include, leave empty for all classes (e.g., ['person', 'car'])\n",
    "\n",
    "# Load the original annotations\n",
    "with open(original_ann_file, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Filter images and annotations by selected classes if specified\n",
    "if selected_classes:\n",
    "    # Get category IDs for the selected classes\n",
    "    category_ids = {cat['id'] for cat in coco_data['categories'] if cat['name'] in selected_classes}\n",
    "\n",
    "    # Filter annotations by category IDs\n",
    "    filtered_annotations = [ann for ann in coco_data['annotations'] if ann['category_id'] in category_ids]\n",
    "\n",
    "    # Get image IDs for the filtered annotations\n",
    "    image_ids = {ann['image_id'] for ann in filtered_annotations}\n",
    "\n",
    "    # Filter images based on these image IDs\n",
    "    filtered_images = [img for img in coco_data['images'] if img['id'] in image_ids]\n",
    "else:\n",
    "    # Use all images and annotations if no classes are specified\n",
    "    filtered_images = coco_data['images']\n",
    "    filtered_annotations = coco_data['annotations']\n",
    "\n",
    "# Shuffle the filtered images randomly\n",
    "random.shuffle(filtered_images)\n",
    "\n",
    "# Limit the number of images to the specified value\n",
    "val_images = filtered_images[:num_images]\n",
    "\n",
    "# Filter annotations for the selected images\n",
    "def filter_annotations(images, annotations):\n",
    "    image_ids = {img['id'] for img in images}\n",
    "    return [ann for ann in annotations if ann['image_id'] in image_ids]\n",
    "\n",
    "val_annotations = filter_annotations(val_images, filtered_annotations)\n",
    "\n",
    "# Create the new JSON structure for validation\n",
    "val_data = {\n",
    "    'images': val_images,\n",
    "    'annotations': val_annotations,\n",
    "    'categories': coco_data['categories']\n",
    "}\n",
    "\n",
    "# Save the new JSON file\n",
    "output_file = '/nas.dbms/asera/PROJECTS/DATASET/COCO/mini-annotations/mini_val2017-2k-5c.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(val_data, f)\n",
    "\n",
    "print(f\"Validation dataset created with {len(val_images)} images.\")\n",
    "if selected_classes:\n",
    "    print(f\"Filtered by classes: {selected_classes}\")\n",
    "else:\n",
    "    print(\"All classes included.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
